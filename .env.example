# Path to your WhisperKit CoreML model directory (Hugging Face identifier, e.g., openai/whisper-large-v2)
WHISPERKIT_MODEL_PATH=openai/whisper-large-v2

# Path to your input folder containing videos (required if not passing as CLI argument)
INPUT_FOLDER=/absolute/path/to/your/video/folder

# Path to output folder for transcripts (optional; if empty, will use INPUT_FOLDER/transcriptions)
OUTPUT_FOLDER=

# Number of parallel workers (optional, default: half your CPU cores)
NUM_WORKERS=4

# Overwrite existing transcripts (true/false, optional, default: false)
OVERWRITE=false

# Output timestamps in transcript (true/false, optional, default: false)
TIMESTAMPS=false

# Language code for transcription (optional, e.g., en, fr, es)
LANGUAGE=
